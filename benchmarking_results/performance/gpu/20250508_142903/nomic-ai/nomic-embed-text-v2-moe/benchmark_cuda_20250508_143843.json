{
    "model_name": "nomic-ai/nomic-embed-text-v2-moe",
    "timestamp": "2025-05-08 14:38:41",
    "device": "cuda",
    "test_sentence_used": "This benchmark evaluates the inference speed and memory footprint of various sentence embedding models when processing a large volume of repeated textual data on different hardware configurations.",
    "prefix_function_name": "none",
    "normalize_embeddings_in_encode_call": false,
    "num_sentences_processed": 100000,
    "batch_size": 64,
    "warmup_runs": 256,
    "ram_psutil_before_load_mb": 469.75,
    "ram_resource_maxrss_before_load_mb": 469.75,
    "effective_device": "cuda",
    "gpu_mem_before_load": {
        "gpu_memory_allocated_mb": 0.0,
        "gpu_memory_peak_allocated_mb": 0.0,
        "gpu_memory_reserved_mb": 0.0,
        "gpu_memory_peak_reserved_mb": 0.0
    },
    "error": "Loading nomic-ai/nomic-embed-text-v2-moe requires you to execute the configuration file in that repo on your local machine. Make sure you have read the code there to avoid malicious use, then set the option `trust_remote_code=True` to remove this error."
}